# 1. Namespace untuk mengisolasi Kafka dan Zookeeper
apiVersion: v1
kind: Namespace
metadata:
  name: kafka
---
# --- Konfigurasi Zookeeper (Dependensi Kafka) ---

# 2. Service untuk Zookeeper
apiVersion: v1
kind: Service
metadata:
  name: zookeeper-svc
  namespace: kafka
  labels:
    app: zookeeper
spec:
  ports:
  - name: client
    port: 2181
    protocol: TCP
  clusterIP: None # Headless service untuk StatefulSet
  selector:
    app: zookeeper
---
# 3. StatefulSet untuk Zookeeper
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
  namespace: kafka
spec:
  serviceName: "zookeeper-svc"
  # Menggunakan 1 replika untuk menghemat sumber daya
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.0.1
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
        # Menentukan permintaan dan batas sumber daya yang rendah
        resources:
          requests:
            cpu: "250m"
            memory: "512Mi"
          limits:
            cpu: "500m"
            memory: "1Gi"
        volumeMounts:
        - name: zookeeper-data
          mountPath: /var/lib/zookeeper/data
        - name: zookeeper-log
          mountPath: /var/lib/zookeeper/log
  volumeClaimTemplates:
  - metadata:
      name: zookeeper-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 2Gi # Ukuran penyimpanan kecil
  - metadata:
      name: zookeeper-log
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
---
# --- Konfigurasi Kafka Broker ---

# 4. Service Internal untuk Kafka (komunikasi antar broker)
apiVersion: v1
kind: Service
metadata:
  name: kafka-svc-internal
  namespace: kafka
  labels:
    app: kafka
spec:
  ports:
  - name: broker
    port: 9092
    protocol: TCP
  clusterIP: None # Headless service untuk StatefulSet
  selector:
    app: kafka
---
# 5. Service Eksternal dengan NodePort untuk Kafka
apiVersion: v1
kind: Service
metadata:
  name: kafka-svc-external
  namespace: kafka
spec:
  type: NodePort
  selector:
    app: kafka
  ports:
  - name: kafka-external
    protocol: TCP
    port: 9094 # Port internal yang akan di-mapping
    targetPort: 9094
    # NodePort diatur secara manual ke 32094 agar mudah diakses
    nodePort: 32094
---
# 6. StatefulSet untuk Kafka Broker
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  serviceName: "kafka-svc-internal"
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      initContainers:
      - name: get-broker-id
        image: busybox:1.28
        command: ['/bin/sh', '-c', "export BROKER_ID=$(hostname | awk -F'-' '{print $2}') && echo \"broker id is $BROKER_ID\" > /var/lib/kafka/data/my-broker-id"]
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.0.1
        ports:
        - name: internal
          containerPort: 9092
        - name: external
          containerPort: 9094
        # --- PERBAIKAN UTAMA ADA DI SINI ---
        # Override the command to use a shell for variable substitution
        command: ["/bin/sh", "-c"]
        args:
          - |
            # Set the advertised listeners with the expanded host IP
            export KAFKA_ADVERTISED_LISTENERS="INTERNAL://kafka-0.kafka-svc-internal.kafka.svc.cluster.local:9092,EXTERNAL://${KAFKA_ADVERTISED_HOST_NAME}:32094"
            
            # Now, execute the original entrypoint from the Confluent image
            /etc/confluent/docker/run
        env:
        # Konfigurasi koneksi ke Zookeeper
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper-svc:2181"
        # Konfigurasi listener internal (dalam cluster) dan eksternal (luar cluster)
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "INTERNAL"
        
        # We REMOVED KAFKA_ADVERTISED_LISTENERS from here because it's now set in the 'args' above.
        
        # Ambil nama host (IP node) dari Downward API. Ini penting untuk NodePort.
        - name: KAFKA_ADVERTISED_HOST_NAME
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
              
        # --- PERBAIKAN LAINNYA ---
        # Broker ID tidak lagi di-hardcode, dibaca dari file yang dibuat oleh initContainer
        # Note: I've updated the file path to avoid conflicts and make it clearer.
        - name: KAFKA_BROKER_ID_COMMAND
          value: "cat /var/lib/kafka/data/my-broker-id"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS
          value: "0"
        resources:
          requests:
            cpu: "500m"
            memory: "1.5Gi"
          limits:
            cpu: "1"
            memory: "2.5Gi"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 5Gi